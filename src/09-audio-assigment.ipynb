{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b536d2af-ef43-4905-8250-e80d7ce9a4db",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfb378-09ea-4d89-8d20-495c464bd802",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ae99b-5837-4c55-b2db-bd7cd12e27cb",
   "metadata": {},
   "source": [
    "Для начала познакомимся с этими записями. \\\n",
    "Установи библиотеку [librosa](https://librosa.org/). Это популярная библиотека для работы с аудио.\n",
    "Визуализируй аудио сигнал файла `0_1_0_1_1_1_0_0.wav` с помощью функции [librosa.display.waveshow](https://librosa.org/doc/main/generated/librosa.display.waveshow.html)\n",
    "График должен быть такой же, как показано ниже (по значениям):\n",
    "\n",
    "![waveform](../misc/images/waveform.png)\n",
    ">Для того, чтобы прослушать это аудио файл, можешь воспользоваться [IPython.display.Audio](http://ipython.org/ipython-doc/stable/api/generated/IPython.display.html#IPython.display.Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241e134b-bb0d-4962-ae6b-80f98f793639",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Код тут\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Путь к аудио файлу\n",
    "audio_path = \"../datasets/waves_yesno 2/0_1_0_1_1_1_0_0.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "226b097f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.signal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zz/zyxvpxvq6csfxvn_n003vsdw00yybg/T/ipykernel_11705/1028651528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Загрузка аудио файла\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Визуализация аудио сигнала\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/lazy_loader/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0msubmod_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{package_name}.{attr_to_modules[name]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0msubmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# If the attribute lives in a file (module) with the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/lazy_loader/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr_to_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0msubmod_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{package_name}.{attr_to_modules[name]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msubmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_loader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.signal'"
     ]
    }
   ],
   "source": [
    "# Загрузка аудио файла\n",
    "audio_signal, sample_rate = librosa.load(audio_path)\n",
    "\n",
    "# Визуализация аудио сигнала\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769806f1-3206-46db-8fb9-f848dd337d64",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfefd4c-72d3-4de7-bb01-0cecd51a3be8",
   "metadata": {},
   "source": [
    "Для классификации обычно использует не просто аудио сигнал, а его частотно-временное представление. Для этого сигнал требуется\n",
    "преобразовать с помощью [оконного преобразования Фурье](https://clck.ru/34JnZD).\n",
    "С помощью функции [librosa.display.specshow](https://librosa.org/doc/main/generated/librosa.display.specshow.html) \n",
    "выведи спектрограмму сигнала. \\\n",
    "График должен быть такой же, как показано ниже (по значениям):\n",
    "![sftp](../misc/images/sftp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb55dc73-3ef5-4839-931d-5da9989a8af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zz/zyxvpxvq6csfxvn_n003vsdw00yybg/T/ipykernel_16205/3415686399.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Код тут\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Вычисление спектрограммы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Визуализация спектрограммы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "# Код тут\n",
    "# Вычисление спектрограммы\n",
    "spectrogram = librosa.feature.melspectrogram(y=audio_signal, sr=sample_rate)\n",
    "\n",
    "# Визуализация спектрограммы\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max), sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba3fcc-00ba-4940-a45c-8fd645210773",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33985db5-672f-4b54-80e2-d9086d3ae24b",
   "metadata": {},
   "source": [
    "C помощью функции [load_dataset](code-samples/audio_utils.py) загрузи датасет. \\\n",
    "Раздели его на train и test c параметрами `test_size=0.2`, `random_state=42`. \\\n",
    "Выведи количество файлов в train и test частях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b8e720-0ea7-455f-a700-c0adf3f9584d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_dataset(directory: str):\n",
    "    sr = None\n",
    "    X, labels, files = [], [], []\n",
    "    for f in glob(directory + \"/*.wav\"):\n",
    "        filename = os.path.basename(f)\n",
    "        name = filename[:-4]\n",
    "        y = [int(label) for label in name.split(\"_\")]\n",
    "        x, sr = librosa.load(f)\n",
    "        X.append(x)\n",
    "        labels.append(y)\n",
    "        files.append(filename)\n",
    "\n",
    "    return X, labels, sr, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bc6d2b-7aae-48b9-898b-acc1b8f808d3",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Код тут\n",
    "X, labels, sr, files = load_dataset(\"../datasets/waves_yesno 2/\")\n",
    "# Разделение выборки на тренировочную и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37448af8-8629-4b6a-ba9e-a5b6474d81d5",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e918fb1-4f37-4336-b4d4-20b4f4fb77d1",
   "metadata": {},
   "source": [
    "Наши аудио записи содержат как речь человека, так и молчание. Для каждой записи нам нужно определить сегменты записи, \n",
    "где человек молчит, а где произносит слова. \\\n",
    "Эта задача называется [Voice Activity Detection (VAD)](https://ru.wikipedia.org/wiki/Voice_Activity_Detection).\n",
    "Придумайте или найдите метод, по которому можно распознавать участки с речью на аудио записи.\n",
    "\n",
    "Например:\n",
    "Запись '0_0_0_1_0_1_1_0.wav' содержит 137592 отсчетов. Сегменты с речью для этой записи (Отмечены красным):\n",
    "[[23996, 32539],\n",
    " [35410, 44925],\n",
    " [49493, 57410],\n",
    " [60458, 68635],\n",
    " [73308, 81278],\n",
    " [84001, 91942],\n",
    " [97381, 104166],\n",
    " [109018, 115573]] \n",
    "![sftp](../misc/images/vad.png)\n",
    "\n",
    "Выведи несколько примеров работы твоего VAD-алгоритма, по аналогии с примером, для других аудио записей. Попробуй добиться\n",
    "наилучшего качества нахождения речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143a8574-daf7-4918-b86a-32f4caa21d75",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Код тут\n",
    "def voice_activity_detection(audio_signal, sample_rate, frame_duration=0.03, energy_threshold=0.01, silence_threshold=0.5):\n",
    "    # Разделение аудио на фреймы\n",
    "    frame_length = int(frame_duration * sample_rate)\n",
    "    frames = librosa.util.frame(audio_signal, frame_length=frame_length, hop_length=frame_length // 2)\n",
    "\n",
    "    # Вычисление энергии для каждого фрейма\n",
    "    energy = np.sum(frames ** 2, axis=0) / frame_length\n",
    "\n",
    "    # Определение речевых и молчащих участков на основе энергии\n",
    "    is_speech = energy > energy_threshold\n",
    "\n",
    "    # Объединение речевых фреймов в сегменты\n",
    "    segments = []\n",
    "    start = None\n",
    "    for i, is_speech_frame in enumerate(is_speech):\n",
    "        if is_speech_frame and start is None:\n",
    "            start = i\n",
    "        elif (not is_speech_frame or i == len(is_speech) - 1) and start is not None:\n",
    "            end = i if is_speech_frame else i - 1\n",
    "            segment_start = start * frame_length\n",
    "            segment_end = end * frame_length\n",
    "            segments.append([segment_start, segment_end])\n",
    "            start = None\n",
    "\n",
    "    # Добавление интервалов молчания между речевыми сегментами\n",
    "    voiced_segments = []\n",
    "    for segment in segments:\n",
    "        if voiced_segments and segment[0] - voiced_segments[-1][1] <= silence_threshold * sample_rate:\n",
    "            voiced_segments[-1][1] = segment[1]\n",
    "        else:\n",
    "            voiced_segments.append(segment)\n",
    "\n",
    "    return voiced_segments\n",
    "\n",
    "# Пример использования\n",
    "audio_path = '../datasets/waves_yesno 2/0_0_0_1_0_1_1_0.wav'\n",
    "audio_signal, sample_rate = librosa.load(audio_path, sr=None)\n",
    "segments = voice_activity_detection(audio_signal, sample_rate)\n",
    "print(f\"Запись '0_0_0_1_0_1_1_0.wav' содержит {audio_signal.shape[0]} отсчетов\", segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7b192-d6f0-4259-959c-833f4ee26cb5",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccfb93-41b9-4b86-b039-753a9c65def6",
   "metadata": {},
   "source": [
    "После того как мы узнали сегменты аудио с речью, то можно перейти к самой задаче классификации. \\\n",
    "Внимательно изучи функцию [make_dataset](code-samples/audio_utils.py). С помощью этой функции cгенерируй X, Y для train и test выборок.\n",
    "Затем попробуй обучить различные классификаторы. Например, SVM или LogisticRegression.\n",
    "Измерь точность (accuracy) классификации на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff76a1e-6d51-4f9e-be04-f2f158369e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(samples, labels, vad_segments):\n",
    "    \"\"\"\n",
    "\n",
    "    :param samples: Список аудио сигналов\n",
    "    :param labels: Список меток (Например для файла '0_0_0_1_0_1_1_0.wav': [0, 0, 0, 1, 0, 1, 1, 0])\n",
    "    :param vad_segments: Список сегментов для каждого аудио сигнала вида:\n",
    "        [\n",
    "            [[23996, 32539], [35410, 44925], ...,],\n",
    "            [[22141, 30259], [34917, 42695], ...,],\n",
    "            ...\n",
    "        ]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    # Проходим по каждому аудио сигналу\n",
    "    for sample in range(len(samples)):\n",
    "        # В аудио сигнале проходим по каждому сегменту с речью\n",
    "        for segment in range(len(vad_segments[sample]) - 1):\n",
    "            start = vad_segments[sample][segment][0]  # Начало сегмента\n",
    "            stop = vad_segments[sample][segment][1]  # Конец сегмента\n",
    "            voice = samples[sample][start:stop]  # Отрезаем сегмент с речью из аудио сигнала и применяем stft\n",
    "            stft = librosa.stft(voice).mean(axis=1)\n",
    "            stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "\n",
    "            X.append(stft_db)  # Добавляем спектрограмму с речью\n",
    "            y.append(labels[sample][segment])  # Добавляем метку для этой спектрограммы\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2569c22-78f3-4af6-985f-c4d44cf4a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код тут"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
